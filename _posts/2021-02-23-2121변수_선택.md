---
title:  "Article 1. 변수 선택 2121"

categories:
  - 빅데이터 분석 기사
tags: 
  - Part 2. 빅데이터 탐색
  - Chapter 1. 데이터 전처리
  - Section 2. 분석 변수 처리
  - Article 1. 변수 선택

toc: true
toc_sticky: true
 
date: 2021-02-23
last_modified_at: 2021-02-25
---

Section 2. [분석 변수 처리]()

# Paragraph 1. 변수(Feature) 개념

- 데이터 모델에서 사용하는 예측을 수행하는 데 사용되는 입력변수이다.

- RDBMS에서 '속성(열)'이라고 부르는 것을 머신 러닝에서는 통계학의 영향으로 '변수(Feature)'라고 한다.

  > 예) '키와 체중' 값으로 '성별' 예측할 때 데이터 세트에는 변수가 3개(키, 체중, 성별) 있다.

- 키, 체중처럼 값이 알려진 값과 성별처럼 값을 예측해야 되는 값은 다른 유형으로 구분한다.

|   유형    | 명칭                                                         |
| :-------: | ------------------------------------------------------------ |
| 알려진 값 | 변수(Feature), 속성(Attribute), 예측변수(Predictor), 차원(Dimension), 관측치(Observation), 독립변수(Independent Variable) |
|  예측 값  | 라벨(Label), 클래스(Class), 못푯값(Target), 반응(Response), 종속변수(Dependent Variable) |

# Paragraph 2. 변수 유형

- 인과관계 및 속성에 따른 변수의 유형을 확인한다.

⬇인과관계

1. 독립변수

   - 다른 변수에 영향을 받지 않고 종속변수에 영향을 주는 변수

   - 연구자가 의도적으로 변화시키는 변수

     > 예) 지역구, IQ

2. 종속변수

   - 다른 변수로부터 영향을 받는 변수

   - 독립변수의 변화에 따라 어떻게 변하는지 연구하는 변수

     > 예) 지역구별 소득, IQ에 따른 시험성적

⬇변수속성

1. 범주형(Categorical)

   - 범위와 순서가 있는 변수

     1. 명목형(Nominal)

        - 명사형으로 변수나 변수의 크기가 순서와 상관없고, 의미가 없이 이름만 의미를 부여할 수 있는 경우

          > 예) 스마트폰 브랜드(삼성=1, LG=2, 애플=3), 현역 구분(현역=1, 예비역=2)

     2. 순서형(Ordinal)

        - 변수가 어떤 기준에 따라 순서에 의미를 부여할 수 있는 경우

          > 병원 수준(의원=1, 종합변원=2, 대학병원=3), 화장실 상태(양호=3, 보통=2, 나쁨=1)

2. 수치형(Measure)

   - 수치로 표현되는 변수

     1. 이산형(Discrete)

        - 변수가 취할 수 있는 값을 하나하나 셀 수 있는 경우

          > 예) 시험문제 중 틀린 개수, 집에 있는 책의 개수

     2. 연속형(Continuous)

        - 변수가 구간 안의 모든 값을 가질 수 있는 경우

          > 예) 몸무게, 키

## Subparagraph 1. 독립변수(Independent Variable)

- 종속변수(결과변수)의 값에 영향을 미쳐 종속변수가 특정한 값을 갖게 되는 원인이 된다고 가정한 변수이다.
- 독립변수는 예측변수(Predictor Variable), 회귀자(Regressor), 통제변수(Controlled Variable), 조작변수(Manipulated Variable), 노출변수(Exposure Variable), 리스크 팩터(Risk Factor), 설명변수(Explanator Variable), 입력변수(Input Variable)라고 불린다
- 기계 학습 혹은 패턴 인식에서는 변수(Feature)라고도 한다.

## Subparagraph 2. 종속변수(Dependent Variable)

- 독립변수에 영향을 받아서 변화하는 종속적인 변수이다.
- 독립변수(실험변수)의 영향을 받아 그 값이 변할 것이라고 가정한 변수이다.

## Subparagraph 3. 변수 간 관계

- 독립변수와 종속변수는 인과 관계를 가지고 있으며 독립변수, 종속변수 모두 연속형, 범주형 자료로 분석이 가능하다.
- 연속형 자료라면 공변량(Covariate)이라 하고, 범주형 자료라면 요인(Factor)이라 한다.

# Paragraph 3. 변수 선택

## Subparagraph 1. 변수 선택(Feature Selection) 개념

변수 선택이란 데이터의 독립변수(x) 중 종속변수(y)에 가장 관련성이 높은 변수(Feature)만을 선정하는 방법이다.

## Subparagraph 2. 변수 선택 특징

- 변수 선택은 사용자가 해석하기 쉽게 모델을 단순화해주고 훈련 시간 축소, 차원의 저주 방지, 과적합을 줄여 일반화를 해주는 장점이 있다.
- 변수 선택을 통하여 모델의 정확도 향상 및 성능 향상을 기대할 수 있다.

## Subparagraph 3. 변수 선택 기법

변수 선택은 예측대상이 되는 분류를 참고하지 않고 변수들만으로 수행하는 비지도 방식과 분류를 참고하여 변수를 선택하는 지도 방식으로도 분류할 수 있다.

|              기법              | 설명                                                         |
| :----------------------------: | ------------------------------------------------------------ |
|    필터 기법(Filter Method)    | 특정 모델링 기법에 의존하지 않고 데이터의 통계적 특성으로부터 변수를 택하는 기법 |
|   래퍼 기법(Wrapper Method)    | 변수의 일부분만을 모델링에 사용하고 그 결과를 확인하는 작업을 반복하면서 변수를 택해나가는 기법 |
| 임베디드 기법(Embedded Method) | 모델 자체에 변수 선택이 포함된 기법                          |

## Subparagraph 4. 변수 선택 기법 상세

### Clause 1. 필터 기법(Filter Method)

특징 변수의 전체 집합(Set of all Features) ➡ 가장 적합한 하위 집합 선택(Selecting the Best subset) ➡ 알고리즘 학습(Learning Algorithm) ➡ 성능 평가(Performance)

- 필터 기법은 데이터의 통계적 측정 방법을 사용하여 변수(Feature)들의 상관관계를 알아낸다.
- 계산속도가 빠르고 변수 간 상관관계를 알아내는 데 적합하여 래퍼 기법을 사용하기 전에 전처리하는 데 사용한다.

⬇필터 기법 사례

|               기법                | 기법 설명                                                    |
| :-------------------------------: | ------------------------------------------------------------ |
|    정보 소득(Information Gain)    | 가장 정보 소득이 높은 속성을 선택하여 데이터를 더 잘 구분하게 되는 것 |
|  카이제곱 검정(Chi-Square Test)   | 카이제곱 분포에 기초한 통계적 방법으로, 관찰된 빈도가 기대되는 빈도와 의미있게 다른지 여부를 검증하기 위해 사용되는 검증 방법 |
|     피셔 스코어(Fisher Score)     | 최대 가능성 방정식을 풀기 위해 통계에 사용되는 뉴턴(Newton)의 방법 |
| 상관계수(Correlation Coefficient) | 두 변수 사이의 통계적 관계를 표현하기 위해 특정한 상관관계의 정도를 수치적으로 나타낸 계수 |

### Clause 2. 래퍼 기법(Wrapper Method)

![래퍼 기법](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKc9LE%2FbtqB8neCh7p%2FTZAUMOgkTUodGGXReGEQX1%2Fimg.png)

- 래퍼 방법은 예측 정확도 측면에서 가장 좋은 성능을 보이는 하위 집합을 선택하는 기법이다.
- 검색 가능한 방법으로 하위 집합을 반복해서 서낵하여 테스트하는 것이므로 `그리디 알고리즘`에 속한다.
- 반복하여 선택하는 방법으로 시간이 오래 걸리고 부분집합의 수가 기하급수적으로 늘어 과적합의 위험이 발생할 수 있다.
- 일반적으로 래퍼 방법은 필터 방법보다 예측 정확도가 높다.
- 변수 선택을 위한 알고리즘과 선택기준을 결정해야 한다.

⬇변수 선택을 위한 알고리즘 유형

|             알고리즘              | 설명                                                         |
| :-------------------------------: | ------------------------------------------------------------ |
|  전진 선택법(Forward Selection)   | • 모형을 가장 많이 향상시키는 변수를 하나씩 점진적으로 추가하는 방법<br />• 비어 있는 상태에서 시작하며 변수 추가 시 선택기준이 향상되지 않으면 변수 추가를 중단 |
| 후진 제거법(Backward Elimination) | • 모두 포함된 상태에서 시작하며 가장 적은 영향을 주는 변수부터 하나씩 제거<br />• 더 이상 제거할 변수가 없다고 판단될 때 변수의 제거를 중단 |
|   단계적 방법(Stepwise Method)    | • 전진 선택과 후진 제거를 함께 사용하는 방법                 |

⬇래퍼 기법 상세

|                    기법                    | 기법 설명                                                    |
| :----------------------------------------: | ------------------------------------------------------------ |
|     RFE(Recursive Feature Elimination)     | • SVM(Support Vector Machine)을 사용하여 재귀적으로 제거하는 방법<br />• 전진 선택, 후진 제거, 단계적 방법 사용 |
|     SFS(Sequential Feature Selection)      | • 그리디 알고리즘으로 빈 부분 집합에서 특성 변수를 하나씩 추가하는 방법 |
|      유전 알고리즘(Genetic Algorithm)      | • 자연 세계의 진화과정에 기초한 계산 모델<br />• 존 홀랜드에 의해서 1975년에 개발된 전역 최적화 기법으로, 최적화 문제를 해결하는 기법 |
|     단변량 선택(Univariate Selection)      | • 하나의 변수선택법으로 각 피처를 개별적으로 검사하여 피처와 반응변수 간 관계의 강도를 결정<br />• 실행 및 이해가 간단하며 일반적으로 데이터에 대한 이해를 높일 때 사용 |
| mRMR(Minimum Redundancy Maximum Relevance) | • 특정 변수의 중복성을 최소화하는 방법으로 종속변수를 잘 예측하면서, 독립변수들과도 중복성이 적은 변수들을 선택하는 방법 |



### Clause 3. 임베디드 기법(Embedded Method)

![임베디드 기법](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsD7G5%2Fbtq0tYVM1Yb%2FpM3opX0nwTPrtFM6rK7BR1%2Fimg.png)

- 임베디드 기법은 모델의 정확도에 기여 하는 변수를 학습한다.
- 좀 더 적은 계수를 가지는 회귀식을 찾는 방향으로 제약조건을 주어 이를 제어한다.

⬇임베디드 기법 사례

|                             기법                             | 설명                                                         |
| :----------------------------------------------------------: | ------------------------------------------------------------ |
| 라쏘(LASSO; Least Absolute Shrinkage and Selection Operator) | • 가중치의 절댓값의 합을 최소화하는 것을 추가적인 제약조건으로 하는 방법<br />• L1-norm을 통해 제약을 주는 방법 |
|                         릿지(Ridge)                          | • 가중치들의 제곱 합을 최소화하는 것을 추가적인 제약조건으로 하는 방법<br />• L2-norm을 통해 제약을 주는 방법 |
|                   엘라스틱 넷(Elastic Net)                   | • 가중치 절댓값의 합과 제곱 합을 동시에 추가적인 제약조건으로 하는 방법<br />• 라쏘(LASSO)와 릿지(Ridge) 두 개를 선형 결합한 방법 |
|                       SelectFromModel                        | • 의사결정나무 기반 알고리즘에서 변수를 선택하는 방법        |

