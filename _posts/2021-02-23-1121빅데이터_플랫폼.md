---
title:  "Article1. 빅데이터 플랫폼"

categories:
  - 빅데이터 분석 기사
tags:
  - Part1. 빅데이터 분석 기획
  - Chapter1. 빅데이터의 이해
  - Section2. 빅데이터 기술 및 제도
  - Article1. 빅데이터 플랫폼

toc: true
toc_sticky: true
 
date: 2021-02-23
last_modified_at: 2021-02-25
---

:back: Section2. [빅데이터 기술 및 제도]()

# Paragraph1. 빅데이터 플랫폼의 개념

- 빅데이터에서 가치를 추출하기 위해 일련의 과정(수집 -> 저장 -> 처리 -> 분석 -> 시각화)을 규격화한 기술
- 특화된 분석(의료, 환경, 범죄, 자동차 등)을 지원하는 빅데이터 플랫폼이 발전하는 추세

# Paragraph2. 빅데이터 플랫폼 구성요소

빅데이터 플랫폼은 크게 수집, 저장, 분석, 활용 단계로 구성된다

1. 데이터 수집
   - 원천 데이터의 정형/반정형/비정형 데이터 수집
   - ETL, Crawler, EAI 등
2. 데이터 저장
   - 정형 데이터, 반정형 데이터, 비정형 데이터 저장
   - RDBMS, NoSQL 등
3. 데이터 분석
   - 텍스트 분석, 머신러닝, 통계, 데이터 마이닝
   - SNS 분석, 예측 분석 등
4. 데이터 활용
   - 데이터 가시화 및 BI, Open API 연계
   - 히스토그램, 인포그래픽 등

# Paragraph3. 빅데이터 플랫폼 데이터 형식

빅데이터 플랫폼의 데이터 형싱은 대표적으로 HTML, XML, JSON, CSV가 있음

1. HTML

   - HyperText Markup Language
   - 웹 페이지를 만들 때 사용되는 문서 형식
   - 텍스트, 태그, 스크립트로 구성

2. XML

   - eXtensible Markup Language
   - SGML 문서 형식을 가진, 다른 특수한 목적을 갖는 마크업 언어를 만드는 데 사용하는 다목적 마크업 언어
   - 데이터 표현을 위해 태그 사용
   - 엘리먼트, 속성, 처리 명령, 엔티티, 주석, CDATE 섹션으로 구성

3. CSV

   - Comma Separated Values
   - 몇 가지 필드를 쉼표로 구분한 텍스트 데이터 및 텍스트 파일

4. JSON

   - JavaScript Object Notation의 약자
   - <키-값>으로 이루어진 데이터 오브젝트를 전달하기 위해 텍스트를 사용하는 개방형 표준 포맷

   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <note>
     <to>Tove</to>
     <from>Jani</from>
     <heading>Reminder</heading>
     <body>Don't forget me this weekend!</body>
   </note>
   ```

   ```json
   {
   	"id": "0001",
   	"type": "donut",
   	"name": "Cake",
   	"ppu": 0.55,
   	"batters":
   		{
   			"batter":
   				[
   					{ "id": "1001", "type": "Regular" },
   					{ "id": "1002", "type": "Chocolate" },
   					{ "id": "1003", "type": "Blueberry" },
   					{ "id": "1004", "type": "Devil's Food" }
   				]
   		},
   	"topping":
   		[
   			{ "id": "5001", "type": "None" },
   			{ "id": "5002", "type": "Glazed" },
   			{ "id": "5005", "type": "Sugar" },
   			{ "id": "5007", "type": "Powdered Sugar" },
   			{ "id": "5006", "type": "Chocolate with Sprinkles" },
   			{ "id": "5003", "type": "Chocolate" },
   			{ "id": "5004", "type": "Maple" }
   		]
   }
   ```

   

# Paragraph4. 빅데이터 플랫폼 구축 소프트웨어

빅데이터 플랫폼 구축을 위한 주요 소프트웨어로는 R, 우지, 플럼, HBase, 스쿱이 있다

1. R
   - 핵심
     - 빅데이터 분석
   - 목적
     - 통계 프로그래밍 언어인 S 언어를 기반으로 만들어진 오픈 소스 프로그래밍 언어
     - 다양한 그래프 패키지들을 통하여 강력한 시각화 기능 제공
2. Oozie
   - 핵심
     - 워크플로우 관리
   - 목적
     - 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템(스케쥴링/모니터링)
     - 맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어
3. Flume
   - 핵심
     - 데이터 수집
   - 목적
     - Event와 Agent를 활용하여 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동
4. HBase
   - 핵심
     - 데이터 수집
   - 목적
     - 컬럼 기반 저장소로 HDFS와 인터페이스 제공
5. Sqoop
   - 핵심
     - 정형 데이터 수집
   - 목적
     - `SQL to Hadoop`의 약자
     - Connector를 사용하여 RDBMS에서 하둡 파일 시스템(HDFS)으로 데이터를 수집하거나, 하둡 파일 시스템에서 관계형 데이터페이스로 데이터를 보내는 기능 수행

### 분산 컴퓨팅 환경 소프트웨어 구성 요소

1. Map Reduce

   - Key -> Value 형태의 데이터 처리

   - Map -> Shuffle -> Reduce 순서대로 데이터 처리

     - Map

       Key-Value 형태로 데이터를 취함

     - Shuffle

       데이터를 통합하여 처리

     - Reduce

       맵 처리된 데이터를 정리

2. YARN

   - 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 관리 플랫폼

   - 리소스 매니저(Master)와 노드 매니저(Slave)로 구성

     - 리소스 매니저

       스케쥴러 역할을 수행하고 클러스터 이용률 최적화를 수행

     - 노드 매니저

       노드 내의 자원을 관리하고 리소스 매니저에게 전달 수행 및 컨테이너를 관리

     - 애플리케이션 마스터

       리소스 매니저와 자원의 교섭을 책임지고, 컨테이너를 실행

     - 컨테이너

       프로그램 구동을 위한 격리 환경을 지원하는 가상화 자원

3. Apache Spark

   - 하둡 기반 대규모 데이터 분산처리시스템
   - 스트리밍 데이터, 온라인 머신러닝 등 실시간 데이터 처리
   - 스칼라, 자바, 파이썬, R 등에 사용 가능

4. HDFS

   - Hadoop Distributed File System의 약자

   - 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템

   - 네임 노드(Master)와 데이터 노드(Slave)로 구성

     - 네임 노드(Master)

       파일 이름, 권한 등의 속성 기록

     - 데이터 노드(Slave)

       일정한 크기로 나눈 블록 형태로 저장

5. Apache Hadoop

   - 분산 파일 시스템(HDFS)과 맵리듀스를 중심으로 다양한 프로그램으로 구성된 하둡 에코시스템을 가짐

   - 클라우드 플랫폼 위에서 클러스터를 구성해 데이터 분석

     > Spark, Hive, YARN, Cassandra, Pig 등

# Paragraph5. 하둡 에코시스템(Hadoop Ecosystem)

## Subparagraph1.  하둡 에코시스템의 수집, 저장, 처리 기술

## Subparagraph2.  하둡 에코 시스템의 데이터 가공 및 분석, 관리를 위한 주요 기술

