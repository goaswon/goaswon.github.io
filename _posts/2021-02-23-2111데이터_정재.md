---
title:  "Article 1. 데이터 정제 2111"

categories:
  - 빅데이터 분석 기사
tags: 
  - Part 2. 빅데이터 탐색
  - Chapter 1. 데이터 전처리
  - Section 1. 데이터 정제
  - Article 1. 데이터 정제

toc: true
toc_sticky: true
 
date: 2021-02-23
last_modified_at: 2021-02-25
---

Section 1. [데이터 정제]()

# Paragraph 1. 데이터 전처리의 중요성

- 데이터 분석 과정에서 데이터 전처리는 반드시 거쳐야 하는 과정이다.
- 전처리 결과가 분석 결과에 직접적인 영향을 주고 있어서 전처리는 반복적으로 수행해야 한다.
- 데이터 분석의 단계 중 가장 많은 시간이 송되는 단계가 데이터 수집과 전처리 단계이다. (분석가는 업무 시간 중 80% 정도를 데이터 수집 및 전처리 과정에 사용)
- 데이터 전처리는 데이터 정제 ➡ 결측값 처리 ➡ 이상값 처리 ➡ 분석 변수 처리 순서로 진행된다.

# Paragraph 2. 데이터 정제(Data Cleansing) 개념

결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업이다.

# Paragraph 3. 데이터 정제 절차

데이터의 정제 절차는 오류 원인 분석, 정제 대상 선정, 정제 방법 결정 순이다.

1. 데이터 오류 원인 분석
   - 원천 데이터의 오류로 인해서 발생하거나 빅데이터 플로우의 문제로부터 발생
2. 데이터 정제 대상 선정
   - 모든 데이터를 대상으로 정제 활동
3. 데이터 정제 방법 결정
   - 오류 데이터를 삭제, 대체, 예측값으로 삽입

## Subparagraph 1. 데이터 요류 원인을 분석

1. 결측값(Missing Value)
   - 설명
     - 필수적인 데이터가 입력되지 않고 누락된 값
   - 오류 처리 방법 예
     - 중심 경향값 넣기(평균값, 중앙값, 최빈값)
     - 분포기반(랜덤에 의하여 자주 나타나는 값 넣기) 처리
2. 노이즈(Noise)
   - 설명
     - 실제는 입력되지 않았지만 입력되었다고 잘못 판단된 값
   - 오류 처리 방법 예
     - 일정 간격으로 이동하면서 주변보다 높거나 낮으면 평균값 대체
     - 일정 범위 중간값 대체
3. 이상값(Outlier)
   - 설명
     - 데이터의 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값
   - 오류 처리 방법 예
     - 하한보다 낮으면 하한값 대체
     - 상한보다 높으면 상한값 대체

## Subparagraph 2. 데이터 정제 대상 선정

- 모든 데이터를 대상으로 정제 활동을 하는 것이 기본이다.
- 특별히 데이터 품질 저하의 위협이 있는 데이터에 대해서는 더 많은 정제 활동을 수행해야 한다.
- 원천 데이터의 위치를 기준으로 분류한다면 내부 데이터보다 외부 데이터가 품질 저하 위협에 많이 노출되어 있으며, 정형 데이터보다는 비정형과 반정형 데이터가 품질 저하 위협에 많이 노출되어 있다.

## Subparagraph 3. 데이터 정제 방법 결정

- 데이터 정제는 오류 데이터값을 정확한 데이터로 수정하거나 삭제하는 과정이다.
- 정제 여부의 점검은 정제 규칙을 이용하여 위반되는 데이터를 검색하는 방법을 사용한다.
- 노이즈와 이상값은 특히 비정형 데이터에서 자주 발생하므로 데이터 특성에 맞는 정제 규칙을 수립하여 점검한다.

1. 삭제
   - 오류 데이터에 대해 전체 또는 부분삭제
   - 무작위적인 삭제는 데이터 활용의 문제를 일으킬 수 있음
2. 대체
   - 오류 데이터를 평균값, 최빈값, 중앙값으로 대체
   - 오류 데이터가 수집된 다른 데이터와 관계가 있는 경우 유용할 수 있으나 그렇지 않은 경우 데이터 활용 시 왜곡이 발생
3. 예측값 삽입
   - 회귀식 등을 이용한 예측값을 생성하여 삽입
   - 예측값을 적용하기 위해서는 정상 데이터 구간에 대해서도 회귀식이 잘 성립되어야 함

# Paragraph 4. 데이터 정제 기술

## Subparagraph 1. 데이터 일관성 유지를 위한 정제 기법

다른 시스템으로부터 들어온 데이터에 대한 일관성을 부여하기 위해 수행한다.

|       기법        | 설명                                                         | 사례                                                         |
| :---------------: | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  변환(Transform)  | 다양한 형태로 표현된 값을 일관된 형태로 변환하는 작업        | • 코드 변환(남/여 ➡ M/F)<br />• 형식 변환(YYYMMDD ➡ YY/MM/DD) |
|   파싱(Parsing)   | 데이터를 정제 규칙을 적용하기 위한 유의미한 최소 단위로 분할하는 작업 | • 주민 등록 번호를 생년월일, 성별로 분할                     |
| 보강(Enhancement) | 변환, 파싱, 수정, 표준화 등을 통한 추가 정보를 반영하는 작업 | • 주민 등록 번호를 통해 성별을 추출한 후 추가 정보 반영      |



## Subparagraph 2. 데이터 정제 기술

- 분산 처리 시스템을 기반으로 데이터를 정제하고 성능을 보장하기 위해 인 메모리(In-Memory) 기반 컴퓨팅 기술을 사용하기도 한다.
- 정제된 데이터는 데이터 변경(분석)에 활용이 된다.

|             기술              | 설명                                                         |
| :---------------------------: | :----------------------------------------------------------- |
|              ETL              | • 수집 대상 데이터를 추출, 가공(변환, 정제)하여 데이터 웨어하우스 및 데이터 마트에 저장하는 기술 |
|     맵리듀스(Map Reduce)      | • 구글에서 대용량 데이터 세트를 분산, 병렬 컴퓨팅에서 처리하거나 생성하기위한 목적으로 만들어진 소프트웨어 프레임워크다.<br />• 모든 데이터를 키-값(Key-Value) 쌍으로 구성, 데이터를 분류<br />• 데이터를 추출하는 맵(Map) 기술과 추출한 데이터를 중복이 없게 처리하는 리듀스(Reduce) 기술로 구성<br />• 배치 형태 처리 방식으로 많은 데이터를 처리할 때 성능이 느림 |
|   스파크/스톰(Spark/Storm)    | • 인 메모리 기반 데이터 처리 방식<br />• 스파크는 맵리듀스를 기반으로 성능을 개선한 것으로서 실시간, 배치 처리 모두 가능하며, 기계 학습과 라이브러리도 지원 가능 |
| CEP(Complex Event Processing) | • 실시간으로 발생하는 이벤트 처리에 대한 결괏값을 수집하고 처리하는 기술<br />• IoT 센싱 데이터, 로그, 음성 데이터 등 실시간 데이터의 처리 기술 |
|           피그(Pig)           | • 대용량 데이터 집합을 분석하기 위한 플랫폼<br />• 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 `피그 라틴`이라는 자체 언어를 제공 |
|          플럼(Flume)          | • 로그 데이터를 수집하고 처리하는 기법<br />• 실시간에 근접하게 데이터를 전처리하고 수집하는 기술 |



# Paragraph 5. 데이터 세분화

## Subparagraph 1. 데이터 세분화(Data Segmentation) 개념

데이터 세분화란 데이터를 기준에 따라 나누고, 선택한 매개변수를 기반으로 유사한 데이터를 그룹화하여 효율적으로 사용할 수 있는 프로세스이다.

## Subparagraph 2. 데이터 세분화 방법

군집화란 이질적인 집단을 몇 개의 동질적인 소집단으로 세분화하는 작업이다. 군집 방법은 크게 계측적 방법과 비 계층적 방법으로 구분한다.

| 방법           | 설명                                                         | 기법                                   |
| -------------- | ------------------------------------------------------------ | -------------------------------------- |
| 계층적 방법    | • 사전에 군집 수를 정하지 않고 단계적으로 단계별 군집결과를 산출하는 방법 | • 응집분석법<br />• 분할분석법         |
| 비 계층적 방법 | • 군집을 위한 소집단의 개수를 정해놓고 각 객체 중 하나의 소집단으로 배정하는 방법 | • 인공신경망 모델<br />• K-평균 군집화 |



## Subparagraph 3. 데이터 세분화 방법 상세

⬇계층적 방법

| 기법       | 설명                                                         |
| ---------- | ------------------------------------------------------------ |
| 응집분석법 | 각 객체를 하나의 소집단으로 간주하고 단계적으로 유사한 소집단들을 합쳐 새로운 소집단을 구성해가는 기법 |
| 분할분석법 | 전체 집단으로부터 시작하여 유사성이 떨어지는 객체들을 분리해가는 기법 |

⬇비 계층적 방법

| 기법            | 설명                                                         |
| --------------- | ------------------------------------------------------------ |
| 인공신경망 모델 | 기계 학습에서 생물학의 신경망으로부터 영감을 얻은 통계학적 학습모델 |
| K-평균 군집화   | K개 소집단의 중심좌표를 이용하여 각 객체와 중심좌표 간의 거리를 산출하고, 가장 근접한 소집단에 배정한 후 해당 소집단의 중심좌표를 업데이트하는 방식으로 군집화하는 방식 |

